{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cea794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install xgboost\n",
    "!{sys.executable} -m pip install hyperopt\n",
    "!{sys.executable} -m pip install ipython-autotime\n",
    "!{sys.executable} -m pip install pandas-profiling\n",
    "!{sys.executable} -m pip install joblib\n",
    "!{sys.executable} -m pip install pdpbox\n",
    "!{sys.executable} -m pip install optuna\n",
    "!{sys.executable} -m pip install lazypredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761d0e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import joblib\n",
    "\n",
    "import warnings\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "\n",
    "warnings.simplefilter(action = 'ignore', category = SettingWithCopyWarning)\n",
    "\n",
    "from sklearn.model_selection import train_test_split, LeaveOneOut\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "plt.style.use('classic')\n",
    "%matplotlib inline\n",
    "\n",
    "import xgboost as xgb\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "from config import *\n",
    "from utils import *\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from numpy import mean\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "sns.set(rc={'figure.figsize':(16,8)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d54d806",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ca665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./Data/Prop_Data\"\n",
    "TRAIN_FILEPATH = './Data/Prop_Data/train'\n",
    "TEST_FILEPATH = './Data/Prop_Data/test'\n",
    "\n",
    "df_cleaned = pd.read_csv('{}/lead_scoring_combined.csv'.format(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b360ac64",
   "metadata": {},
   "source": [
    "# Data Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a74c384",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First Data Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_cleaned,\n",
    "                                                    df_cleaned[LABEL],\n",
    "                                                    random_state = 0,\n",
    "                                                    test_size = 0.1)\n",
    "\n",
    "print('X_train shape is {}'.format(X_train.shape))\n",
    "print('X_test shape is {}'\n",
    "      .format(X_test.shape))\n",
    "print('y_train shape is {}'.format(y_train.shape))\n",
    "print('y_test shape is {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccaee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Split\n",
    "X_train2, X_calibrated, y_train2, y_calibrated = train_test_split(X_train,\n",
    "                                                                y_train, \n",
    "                                                                test_size=1/9, \n",
    "                                                                random_state=0)\n",
    "# 0.125 x 0.9 = 0.1\n",
    "\n",
    "print('X_train2 shape is {}'.format(X_train2.shape))\n",
    "print('X_calibrated shape is {}'\n",
    "      .format(X_calibrated.shape))\n",
    "print('y_train2 shape is {}'.format(y_train2.shape))\n",
    "print('y_calibrated shape is {}'.format(y_calibrated.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2947af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thrid Split\n",
    "X_train3, X_val, y_train3, y_val = train_test_split(X_train2, y_train2, \n",
    "                                                    test_size=0.2, random_state=0)\n",
    "# 0.125 x 0.9 = 0.1\n",
    "\n",
    "print('X_train3 shape is {}'.format(X_train3.shape))\n",
    "print('X_val shape is {}'\n",
    "      .format(X_val.shape))\n",
    "print('y_train3 shape is {}'.format(y_train3.shape))\n",
    "print('y_val shape is {}'.format(y_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7b1317",
   "metadata": {},
   "source": [
    "## Save Data Splits into Data Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f57c65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Split\n",
    "X_train.to_csv('{}/train.csv'.format(TRAIN_FILEPATH),index=False)\n",
    "X_test.to_csv('{}/test.csv'.format(TEST_FILEPATH),index=False)\n",
    "y_train.to_csv('{}/train_labels.csv'.format(TRAIN_FILEPATH),index=False)\n",
    "y_test.to_csv('{}/test_labels.csv'.format(TEST_FILEPATH),index=False)\n",
    "\n",
    "# Second Split\n",
    "X_train2.to_csv('{}/train2.csv'.format(TRAIN_FILEPATH),index=False)\n",
    "y_train2.to_csv('{}/train2_label.csv'.format(TRAIN_FILEPATH),index=False)\n",
    "X_calibrated.to_csv('{}/calibrated.csv'.format(TEST_FILEPATH),index=False)\n",
    "y_calibrated.to_csv('{}/calibrated_labels.csv'.format(TEST_FILEPATH),index=False)\n",
    "\n",
    "# Third Split\n",
    "X_train3.to_csv('{}/train3.csv'.format(TRAIN_FILEPATH),index=False)\n",
    "X_val.to_csv('{}/validation.csv'.format(TEST_FILEPATH),index=False)\n",
    "y_train3.to_csv('{}/train3_label.csv'.format(TRAIN_FILEPATH),index=False)\n",
    "y_val.to_csv('{}/validation_label.csv'.format(TEST_FILEPATH),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1336ed",
   "metadata": {},
   "source": [
    "# Create Propensity Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ae6cf9",
   "metadata": {},
   "source": [
    "### Define Initial Parameters and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8eb8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'base_score': np.mean(X_train[LABEL]),\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric':'auc',\n",
    "    'max_depth':6\n",
    "}\n",
    "\n",
    "FEATURES = [\n",
    "       'customer_request_call_count', 'customer_request_no_pick_up_count', 'customer_request_call_attempt_count',            \n",
    "       'quote_created_before_count',\n",
    "       'scv_policy_issued_nfc_count', 'scv_policy_cancelled_count',\n",
    "       'scv_policy_inforce_count', 'scv_policy_gi_count', 'scv_policy_li_count',     \n",
    "       'age_at_quote', 'quotation_promo_code_value', 'quote_saved_quote_indicator', \n",
    "       'update_timediff',\n",
    "       'update_flag',\n",
    "       'since_first_quote', 'since_latest_quote', 'since_first_policy', 'since_latest_policy',\n",
    "       'product_type_Big 3 Critical Illness', 'product_type_HDBFire',\n",
    "       'product_type_HDBFire-Home', 'product_type_Home', 'product_type_Life',\n",
    "       'product_type_MCycle', 'product_type_Maid', 'product_type_Motor',\n",
    "       'product_type_other', 'device_type_desktop', 'device_type_mobile',\n",
    "       'applicant_gender_F', 'applicant_gender_M', 'applicant_gender_U',\n",
    "       'nric_type_FOREIGNER', 'nric_type_SGPR']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac0526f",
   "metadata": {},
   "source": [
    "## Fit XGBoost Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f386ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = xgb.XGBClassifier(**params, random_state = 0)\n",
    "nb_model.fit(X_train[[i for i in df_cleaned.columns if i in FEATURES]], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46fb8ee",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b12f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train = nb_model.predict(X_train[nb_model.get_booster().feature_names])\n",
    "preds_train_proba = nb_model.predict_proba(X_train[nb_model.get_booster().feature_names])[:,1]\n",
    "\n",
    "preds_test = nb_model.predict(X_test[nb_model.get_booster().feature_names])\n",
    "preds_test_proba = nb_model.predict_proba(X_test[nb_model.get_booster().feature_names])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa11254",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval-metrics\n",
    "accuracy = round(accuracy_score(y_test, predicted_labels), 3)\n",
    "precision = round(precision_score(y_test, predicted_labels), 3)\n",
    "recall = round(recall_score(y_test, predicted_labels), 3)\n",
    "roc_auc = round(roc_auc_score(y_test,predicted_labels), 3)\n",
    "print('Model evaluation: Accuracy: {} / Precision: {} / Recall: {} / roc_auc: {}'.format(accuracy,\n",
    "                                                         precision,recall, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab45690",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = round(accuracy_score(y_train, preds_train), 3)\n",
    "test_accuracy = round(accuracy_score(y_test, preds_test), 3)\n",
    "\n",
    "train_auc = round(roc_auc_score(y_train, preds_train_proba), 3)\n",
    "test_auc = round(roc_auc_score(y_test, preds_test_proba), 3)\n",
    "\n",
    "\n",
    "print('Model evaluation: Train Accuracy: {} / Test Accuracy: {} / Train roc_auc: {} / Test roc_auc: {}'.format(train_accuracy, test_accuracy, train_auc, test_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7590a0d9",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa5c2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "OUTPUT_PATH = './model_results/prop_model'\n",
    "MODEL_NAME = 'prop_model'\n",
    "DATE = '_16092021'\n",
    "prop_model = joblib.dump(nb_model,  '{}/{}{}{}'.format(OUTPUT_PATH,MODEL_NAME,DATE))\n",
    "prop_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c6cda0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132d3218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "083e54f0",
   "metadata": {},
   "source": [
    "# Model Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4959774",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10638e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_types = ['gain', 'total_gain'\n",
    "#                     , 'cover', 'gain', 'total_cover'\n",
    "                   ]\n",
    "\n",
    "for typ in  importance_types:\n",
    "    fig, ax = plt.subplots(figsize=(16,20))\n",
    "    xgb.plot_importance(nb_model, importance_type = typ, height = 0.8, max_num_features = 20, show_values = False, title = typ, ax = ax)\n",
    "    plt.subtitle=typ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a5b1dd",
   "metadata": {},
   "source": [
    "## PDP Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d38a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "from pdpbox import pdp, get_dataset, info_plots\n",
    "def plot_pdp(model, df, feature):\n",
    "    \n",
    "    # Create the data that we will plot\n",
    "    pdp_goals = pdp.pdp_isolate(model=model, dataset=df, model_features=df.columns.tolist(), feature=feature)\n",
    "    # plot it\n",
    "    pdp.pdp_plot(pdp_goals, feature, cluster=False, n_cluster_centers=None, plot_lines=False,\n",
    "                figsize = (5,5)\n",
    "#                  , plot_pts_dist=True\n",
    "#                  ,x_quantile=True, show_percentile=True\n",
    "                )   \n",
    "    plt.show()\n",
    "    \n",
    "feature_important = nb_model.get_booster().get_score(importance_type='gain')\n",
    "top_feature = sorted(feature_important, key = feature_important.get, reverse = True)\n",
    "print(top_feature[0:20])\n",
    "\n",
    "for feature in top_feature[0:20]:\n",
    "    plot_pdp(nb_model, X_train[X_train['update_timediff']<20000][nb_model.get_booster().feature_names], feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0624a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_important = nb_model.get_booster().get_score(importance_type='gain')\n",
    "top_feature = sorted(feature_important, key = feature_important.get, reverse = True)\n",
    "print(top_feature[0:20])\n",
    "\n",
    "# top_important = X_train_processed.columns.values[np.argsort(best_model.feature_importances_)[-10:][::-1]]\n",
    "for feature in top_feature[0:20]:\n",
    "    plot_pdp(nb_model, X_train[X_train['update_timediff']<20000][nb_model.get_booster().feature_names], feature)\n",
    "#     plot_pdp(nb_model, X_train[nb_model.get_booster().feature_names], feature)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700a46a2",
   "metadata": {},
   "source": [
    "## Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6064f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(X_train[X_train[LABEL]==1]['update_timediff']/60, label = 'converted')\n",
    "\n",
    "sns.distplot(X_train[X_train[LABEL]==0]['update_timediff']/60, label = 'not_converted')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77694879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train['update_timediff_bin'] = (X_train['update_timediff'] > 0)*1\n",
    "\n",
    "sns.distplot(X_train[X_train[LABEL]==1]['age_at_quote'], label = 'converted')\n",
    "\n",
    "sns.distplot(X_train[X_train[LABEL]==0]['age_at_quote'], label = 'not_converted')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb3a0a2",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4634e66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_test, preds_test)\n",
    "# print('Intercept: ' + str(logreg.intercept_))\n",
    "# print('Regression: ' + str(logreg.coef_))\n",
    "# print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))\n",
    "# print(classification_report(y_true, y_pred) )\n",
    "# # print 100*'-'\n",
    "fig, ax = plt.subplots(figsize=(12,10))\n",
    "confusion_matrix_df = pd.DataFrame(confusion_matrix)\n",
    "heatmap = sns.heatmap(confusion_matrix_df, annot=True, annot_kws={\"size\": 20}, fmt=\"d\")\n",
    "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize = 14)\n",
    "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize = 14)\n",
    "plt.ylabel('True label', fontsize = 20 ,weight='heavy')\n",
    "plt.xlabel('Predicted label', fontsize = 20,weight='heavy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95c2cd1",
   "metadata": {},
   "source": [
    "## Predicted Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c83450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the predicted probabilities for score 1\n",
    "y_score = nb_model.predict_proba( X_test[nb_model.get_booster().feature_names] )\n",
    "y_pred_prob = y_score[:, 1]\n",
    "\n",
    "# histogram of predicted probabilities\n",
    "sns.distplot(y_pred_prob, bins=10, kde = True)\n",
    "plt.xlim(0, 1)\n",
    "plt.title('Histogram of predicted probabilities')\n",
    "plt.xlabel('Predicted probability')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f15164",
   "metadata": {},
   "source": [
    "## PP Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faef0eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pp plot function\n",
    "def decile_plot(df, prediction_col, actual_col, what):\n",
    "    '''\n",
    "    df: The dataframe with all relevant columns\n",
    "    prediction_col: Column of predictions.\n",
    "    actual_col: The truth value of the prediction column\n",
    "    what: Column name of whatever you're plotting\n",
    "    '''\n",
    "    df['preds_decile'] = pd.qcut(x = df[prediction_col], q= 10, labels = False)\n",
    "    avg_actuals = []\n",
    "    avg_preds = []\n",
    "   \n",
    "    for i in range(10):\n",
    "        avg_actual = df[df['preds_decile']==i][actual_col].mean()\n",
    "        avg_pred = df[df['preds_decile']==i][prediction_col].mean()\n",
    "        avg_actuals.append(avg_actual)\n",
    "        avg_preds.append(avg_pred)\n",
    "       \n",
    "    plt.plot(np.arange(1,11), avg_preds, label = 'predicted')\n",
    "    plt.plot(np.arange(1,11), avg_actuals, label = 'actual')\n",
    "    plt.xlabel('Predicted {} decile'.format(what))\n",
    "    plt.ylabel('Average {}'.format(what))\n",
    "    plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0c195d",
   "metadata": {},
   "source": [
    "## Tree output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1539afc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out 1 tree\n",
    "tree_list = nb_model.get_booster().get_dump()\n",
    "num_trees = len(tree_list)\n",
    "print(num_trees)\n",
    "print (tree_list [0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
